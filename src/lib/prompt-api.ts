/**
 * í”„ë¡¬í”„íŠ¸ ê°œì„  API ë¡œì§ ëª¨ë“ˆ
 * NextRequest/NextResponseì™€ ë¶„ë¦¬í•˜ì—¬ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥í•œ ìˆœìˆ˜ í•¨ìˆ˜ë“¤
 */

import { GoogleGenerativeAI } from "@google/generative-ai";
import type {
	PromptImprovementRequest,
	PromptImprovementResponse,
	AIProvider,
} from "@/types/api";
import { ScoringService } from "@/lib/scoring/ScoringService";
import type { PromptComparisonAnalysis } from "@/types/scoring";
import {
	improvePromptInDemoMode,
	isDemoModeRequired,
} from "@/lib/demo-prompt-improver";

/** í”„ë¡¬í”„íŠ¸ ê°œì„ ì„ ìœ„í•œ ì‹œìŠ¤í…œ ë©”ì‹œì§€ */
const SYSTEM_PROMPT = `You are an expert prompt engineer. Your task is to improve user prompts to get better responses from AI coding assistants.

Transform the user's prompt by:
1. Adding clear context and requirements
2. Specifying the desired output format
3. Including relevant constraints or considerations
4. Making the request more structured and actionable

Guidelines:
- Make prompts more specific and detailed
- Add context about the programming language, framework, or domain
- Specify expected output format (code, explanation, examples)
- Include error handling, testing, or performance considerations when relevant
- Maintain the original intent while making it more effective

Return only the improved prompt in Korean, without any additional explanation or meta-text.`;

/** Google Geminië¥¼ ì‚¬ìš©í•œ í”„ë¡¬í”„íŠ¸ ê°œì„  */
export async function improveWithGemini(
	prompt: string,
	apiKey: string
): Promise<string> {
	try {
		const genAI = new GoogleGenerativeAI(apiKey);
		const model = genAI.getGenerativeModel({ model: "gemini-1.5-pro" });

		const result = await model.generateContent(
			`${SYSTEM_PROMPT}\n\nê°œì„ í•  í”„ë¡¬í”„íŠ¸:\n${prompt}`
		);
		const response = await result.response;
		const improvedPrompt = response.text();

		if (!improvedPrompt || improvedPrompt.trim().length === 0) {
			throw new Error("ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.");
		}

		return improvedPrompt.trim();
	} catch (error) {
		console.error("Gemini API ì—ëŸ¬:", error);
		throw new Error(
			`Gemini API ìš”ì²­ ì‹¤íŒ¨: ${
				error instanceof Error ? error.message : "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜"
			}`
		);
	}
}

/** ìš”ì²­ ë°ì´í„° ìœ íš¨ì„± ê²€ì¦ */
export function validateRequest(request: unknown): {
	isValid: boolean;
	error?: string;
} {
	if (!request || typeof request !== "object") {
		return { isValid: false, error: "ì˜ëª»ëœ ìš”ì²­ í˜•ì‹ì…ë‹ˆë‹¤." };
	}

	// íƒ€ì… ê°€ë“œë¥¼ í†µí•œ ì•ˆì „í•œ ì†ì„± ì ‘ê·¼
	const requestObj = request as Record<string, unknown>;

	if (!requestObj.prompt || typeof requestObj.prompt !== "string") {
		return { isValid: false, error: "í”„ë¡¬í”„íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤." };
	}

	if (requestObj.prompt.trim().length === 0) {
		return { isValid: false, error: "ë¹ˆ í”„ë¡¬í”„íŠ¸ëŠ” ê°œì„ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤." };
	}

	if (requestObj.prompt.length > 2000) {
		return { isValid: false, error: "í”„ë¡¬í”„íŠ¸ê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤. (ìµœëŒ€ 2000ì)" };
	}

	return { isValid: true };
}

/** Gemini API í‚¤ í™•ì¸ ë° ë°˜í™˜ */
export function getGeminiApiKey(body: PromptImprovementRequest): string {
	const geminiKey = process.env.GEMINI_API_KEY || body.geminiKey;

	if (!geminiKey) {
		throw new Error(
			"Gemini API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” ìš”ì²­ì— API í‚¤ë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”."
		);
	}

	return geminiKey;
}

/** í”„ë¡¬í”„íŠ¸ ê°œì„  ë©”ì¸ ë¡œì§ (ì ìˆ˜í™” í¬í•¨) */
export async function processPromptImprovement(
	request: PromptImprovementRequest
): Promise<
	PromptImprovementResponse & {
		scoringAnalysis?: PromptComparisonAnalysis;
		isDemoMode?: boolean;
	}
> {
	const startTime = Date.now();

	// ìš”ì²­ ìœ íš¨ì„± ê²€ì¦
	const validation = validateRequest(request);
	if (!validation.isValid) {
		throw new Error(validation.error!);
	}

	let improvedPrompt: string;
	let provider: AIProvider;
	let isDemoMode = false;

	try {
		// Gemini API í‚¤ í™•ì¸
		const geminiKey = getGeminiApiKey(request);

		// API í‚¤ê°€ ìœ íš¨í•œì§€ ì²´í¬í•˜ê³  Demo ëª¨ë“œ í•„ìš” ì—¬ë¶€ íŒë‹¨
		if (isDemoModeRequired(geminiKey)) {
			console.log("ğŸ­ Demo ëª¨ë“œë¡œ ì „í™˜: API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤.");
			const demoResult = await improvePromptInDemoMode(request.prompt);
			improvedPrompt = demoResult.improvedPrompt;
			provider = "demo";
			isDemoMode = true;
		} else {
			// Gemini APIë¥¼ í†µí•œ í”„ë¡¬í”„íŠ¸ ê°œì„  ì‹œë„
			improvedPrompt = await improveWithGemini(request.prompt, geminiKey);
			provider = "gemini";
		}
	} catch (apiError) {
		console.warn("ğŸš¨ API í˜¸ì¶œ ì‹¤íŒ¨, Demo ëª¨ë“œë¡œ fallback:", apiError);

		// API ì˜¤ë¥˜ ì‹œ Demo ëª¨ë“œë¡œ fallback
		const demoResult = await improvePromptInDemoMode(request.prompt);
		improvedPrompt = demoResult.improvedPrompt;
		provider = "demo-fallback";
		isDemoMode = true;
	}

	const processingTime = Date.now() - startTime;

	// ê¸°ë³¸ ì‘ë‹µ ê°ì²´ ìƒì„±
	const response: PromptImprovementResponse & { isDemoMode?: boolean } = {
		improvedPrompt,
		provider,
		originalPrompt: request.prompt,
		processingTime,
		isDemoMode,
	};

	// ì ìˆ˜í™” ì‹œìŠ¤í…œ í™œì„±í™” ì‹œ ë¶„ì„ ìˆ˜í–‰ (Demo ëª¨ë“œì—ì„œë„ ë™ì‘)
	let scoringAnalysis: PromptComparisonAnalysis | undefined;
	if (process.env.ENABLE_IMPROVEMENT_SCORING === "true") {
		try {
			const scoringService = new ScoringService();
			scoringAnalysis = await scoringService.analyzeImprovement(
				request.prompt,
				improvedPrompt,
				request.scoringConfig
			);

			// ì ìˆ˜ íˆìŠ¤í† ë¦¬ì— ì €ì¥
			await scoringService.saveScore(scoringAnalysis);

			const modeIndicator = isDemoMode ? "ğŸ­ Demo" : "ğŸ¤– AI";
			console.log(
				`ğŸ“Š ${modeIndicator} ê°œì„  ì ìˆ˜: ${(
					scoringAnalysis.improvementScore.overallScore * 100
				).toFixed(1)}ì  (${scoringAnalysis.improvementScore.grade})`
			);
		} catch (scoringError) {
			console.warn("ì ìˆ˜í™” ì²˜ë¦¬ ì‹¤íŒ¨:", scoringError);
			// ì ìˆ˜í™” ì‹¤íŒ¨ëŠ” ì „ì²´ í”„ë¡œì„¸ìŠ¤ë¥¼ ì¤‘ë‹¨ì‹œí‚¤ì§€ ì•ŠìŒ
		}
	}

	return {
		...response,
		scoringAnalysis,
	};
}

/** API ìƒíƒœ ì •ë³´ */
export function getApiStatus() {
	return {
		status: "OK",
		endpoint: "/api/improve",
		methods: ["POST"],
		provider: "gemini",
		version: "1.0.0",
	};
}
